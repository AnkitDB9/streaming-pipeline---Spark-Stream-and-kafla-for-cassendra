# Enhanced Multi-Source Streaming Pipeline

## ğŸ—ï¸ Clean Project Structure

```
kafka_cassendra/
â”œâ”€â”€ docker-compose.yml                           # Complete infrastructure setup
â”œâ”€â”€ debezium-employee-connector.json            # PostgreSQL CDC connector
â”œâ”€â”€ cassandra-connector.json                    # Cassandra source connector
â”œâ”€â”€ init-scripts/
â”‚   â”œâ”€â”€ 01-init-db.sql                          # PostgreSQL setup
â”‚   â””â”€â”€ 02-employee-activity.sql                # Employee tables
â”œâ”€â”€ cassandra-init/
â”‚   â””â”€â”€ 01-keyspace-tables.cql                  # Cassandra setup
â”œâ”€â”€ hive-scripts/
â”‚   â””â”€â”€ create_tables.sql                       # Hive analytics tables
â”œâ”€â”€ spark-streaming/
â”‚   â”œâ”€â”€ multi_source_streaming_processor.py     # Main Spark application
â”‚   â””â”€â”€ requirements.txt                        # Python dependencies
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup-enhanced.sh                       # Complete setup script
â”‚   â”œâ”€â”€ employee-activity-generator.py          # PostgreSQL data generator
â”‚   â””â”€â”€ cassandra-activity-generator.py         # Cassandra data generator
â”œâ”€â”€ README.md                                   # Project overview
â”œâ”€â”€ PROJECT_DOCUMENTATION.md                   # Detailed documentation
â””â”€â”€ KAFKA_LEARNING_MANUAL.md                   # Kafka concepts
```

## ğŸ¯ Architecture Components

### Data Sources
- **PostgreSQL**: Employee master data
- **Cassandra**: High-volume activity data

### Streaming Pipeline
- **Kafka**: Message broker with multiple topics
- **Debezium**: PostgreSQL CDC connector
- **Cassandra Connector**: Activity data streaming
- **Spark Streaming**: Multi-source processor with Hudi integration

### Storage & Analytics
- **HDFS**: Distributed file storage
- **Apache Hudi**: Solves small files problem
- **Hive**: SQL analytics layer

## ğŸš€ Quick Start

1. **Setup Infrastructure**:
   ```bash
   chmod +x scripts/setup-enhanced.sh
   ./scripts/setup-enhanced.sh
   ```

2. **Start Streaming**:
   ```bash
   python3 spark-streaming/multi_source_streaming_processor.py
   ```

3. **Generate Data**:
   ```bash
   # Terminal 1
   python3 scripts/employee-activity-generator.py
   
   # Terminal 2  
   python3 scripts/cassandra-activity-generator.py
   ```

## ğŸ“Š Output Topics

- `processed-employees` - Enriched employee data
- `processed-activities` - Enriched activity data  
- `hourly-activity-aggregations` - Real-time hourly metrics
- `daily-device-aggregations` - Device usage patterns

## ğŸ”§ Key Features

- âœ… Multi-database streaming (PostgreSQL + Cassandra)
- âœ… Real-time transformations and aggregations
- âœ… Small files problem solved with Apache Hudi
- âœ… HDFS storage with Hive analytics
- âœ… Fault-tolerant processing with checkpointing
- âœ… Exactly-once processing semantics
